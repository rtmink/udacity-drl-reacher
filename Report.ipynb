{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Agent on Unity Environment\n",
    "\n",
    "---\n",
    "\n",
    "## Start the Environment\n",
    "\n",
    "Below assumes that one has followed the instruction on the README file such that the Unity environment is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "env = UnityEnvironment(file_name='Reacher.app')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain brains which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "   1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   5.75471878e+00  -1.00000000e+00\n",
      "   5.55726624e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "  -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm used is based on [Deep Deterministic Policy Gradients (DDPG)](https://arxiv.org/abs/1509.02971). Specifically, it is a distributed version of the algorithm referred to as D3PG which is mentioned [here](https://openreview.net/forum?id=SyZipzbCb). \n",
    "\n",
    "In the aforementioned paper, it is referred to as an \"Actor-Critic\" method which involves an \"Actor\" which acts as a policy network and a \"Critic\" which acts as a value network. The \"Actor\" chooses an action given a state and the \"Critic\" informs the \"Actor\" which action in a given state should have its probability of occurring increased because it leads to a high reward and vice versa.\n",
    "\n",
    "The hyperparameters are mostly inspired by the first [paper](https://arxiv.org/abs/1509.02971):\n",
    "\n",
    "|Hyperparameters|Value|\n",
    "|---|---|\n",
    "|Replay Buffer size|1e6|\n",
    "|Batch size|512|\n",
    "|Discount factor (gamma)|0.99|\n",
    "|Soft update parameter (tau)|1e-3|\n",
    "|Actor learning rate|5e-4|\n",
    "|Critic learning rate|5e-4|\n",
    "|Weight decay|0|\n",
    "|Ornstein-Uhlenbeck theta|0.15|\n",
    "|Ornstein-Uhlenbeck sigma|0.2|\n",
    "|Number of layers|2|\n",
    "|Number of units for first hidden layer|400|\n",
    "|Number of units for second hidden layer|300|\n",
    "\n",
    "with the exception of the batch size and learning rates which were obtained through hyperparameter search.\n",
    "\n",
    "Batch sizes of 64, 128, 256, 512, and 1024 were tested and 512 performed the best.\n",
    "\n",
    "Learning rates of 1e-2, 5e-3, 1e-3, 5e-4, 1e-4 and 1e-5 were tested for both the \"Actor\" and \"Critic\" networks and 5e-4 performed the best.\n",
    "\n",
    "Lastly, weight decay of 1e-2 as used in the first paper significantly slowed down learning, and thus the weight decay was set to 0.\n",
    "\n",
    "The network architecture for both the \"Actor\" and \"Critic\" is based on the one from the first paper. It consists of two hidden fully-connected layers with 400 and 300 units, respectively. The action is used as an input to the second hidden layer of the \"Critic\". The tanh activation function is used for the output layer of the \"Actor\" to bound the value between -1 and 1. ReLU  is used in all other hidden layers. Lastly, batch normalization is applied to the state input and all layers in \"Actor\" and all layers prior to the action input in \"Critic\" such that it has a norm of 1.\n",
    "\n",
    "Ornstein-Uhlenbeck process is used to help with temporally correlated exploration. The implementation is borrowed from Udacity's [implementation](https://github.com/udacity/deep-reinforcement-learning/blob/master/ddpg-pendulum/ddpg_agent.py). However, during experimentation, it was discovered that the use of random number from a uniform distribution `random.random()` was harmful to learning. The use of random number from a normal distribution, on the other hand, allowed for fast learning convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Initialize the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d3pg import Controller\n",
    "\n",
    "seed = 69\n",
    "\n",
    "# initialize the algorithm controller\n",
    "controller = Controller(state_size, action_size, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import deque\n",
    "import torch\n",
    "\n",
    "def train_agent(env, \n",
    "                brain_name, \n",
    "                n_episodes=1000, \n",
    "                n_timesteps=1000, \n",
    "                print_every_n_episode=5,\n",
    "                learn_every_n_timestep=20,\n",
    "                n_learning=10,\n",
    "                passing_score=30, \n",
    "                actor_model_path=\"actor.pt\",\n",
    "                critic_model_path=\"critic.pt\"):\n",
    "    \n",
    "    # initialize start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # initialize score trackers\n",
    "    scores = []\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        \n",
    "        # initialize agent scores (one for each agent)\n",
    "        agent_scores = np.zeros(num_agents)\n",
    "        \n",
    "        # reset the environment\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        \n",
    "        # reset the controller\n",
    "        controller.reset()\n",
    "\n",
    "        # get the current states (one for each agent)\n",
    "        states = env_info.vector_observations\n",
    "        \n",
    "        for timestep in range(n_timesteps):\n",
    "            # select actions (one for each agent)\n",
    "            actions = controller.act(states)\n",
    "                \n",
    "            # send actions to the environment\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            \n",
    "            # get next states\n",
    "            next_states = env_info.vector_observations\n",
    "            \n",
    "            # get rewards\n",
    "            rewards = env_info.rewards\n",
    "            \n",
    "            # get indicators if any episode finishes\n",
    "            dones = env_info.local_done\n",
    "            \n",
    "            # save experiences collected by agents\n",
    "            controller.save_experience(states, actions, rewards, next_states, dones)\n",
    "                \n",
    "            # learn m times every n timestep\n",
    "            if (timestep + 1) % learn_every_n_timestep == 0:\n",
    "                controller.learn(n_learning)\n",
    "            \n",
    "            # accumulate rewards for each agent\n",
    "            agent_scores += rewards\n",
    "            \n",
    "            # roll over to the next states\n",
    "            states = next_states\n",
    "            \n",
    "            # exit loop if any of the episodes finishes\n",
    "            if np.any(dones):\n",
    "                break\n",
    "        \n",
    "        # average scores over agents and add it to the score lists\n",
    "        average_score_over_agents = np.mean(agent_scores)\n",
    "        scores.append(average_score_over_agents)\n",
    "        scores_deque.append(average_score_over_agents)\n",
    "        average_score_over_100_episodes = np.mean(scores_deque)\n",
    "        \n",
    "        # print results\n",
    "        print(\"\\rEpisode {:4d}/{} \\t Current score: {:2.4f} | Avg score over 100 episodes: {:2.4f}\".format(i_episode, n_episodes, average_score_over_agents, average_score_over_100_episodes), end=\"\")\n",
    "        \n",
    "        if i_episode % print_every_n_episode == 0:\n",
    "            print(\"\\rEpisode {:4d}/{} \\t Current score: {:2.4f} | Avg score over 100 episodes: {:2.4f}\".format(i_episode, n_episodes, average_score_over_agents, average_score_over_100_episodes))\n",
    "            \n",
    "            minutes, seconds = utils.get_minutes_and_seconds_from_start_time(start_time)\n",
    "            print(\"Elapsed time: {:3d} minutes {:2d} seconds\\n\".format(minutes, seconds))\n",
    "        \n",
    "        if average_score_over_100_episodes >= passing_score:\n",
    "            print(\"\\rThe environment is solved in {} episodes with an average score of {:2.4f} over 100 episodes\".format(i_episode, average_score_over_100_episodes))\n",
    "            \n",
    "            minutes, seconds = utils.get_minutes_and_seconds_from_start_time(start_time)\n",
    "            print(\"Elapsed time: {:3d} minutes {:2d} seconds\".format(minutes, seconds))\n",
    "        \n",
    "            # save models\n",
    "            torch.save(controller.actor_local.state_dict(), actor_model_path)\n",
    "            torch.save(controller.critic_local.state_dict(), critic_model_path)\n",
    "            \n",
    "            break\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from workspace_utils import active_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode    5/1000 \t Current score: 0.8735 | Avg score over 100 episodes: 0.9025\n",
      "Elapsed time:   1 minutes 30 seconds\n",
      "\n",
      "Episode   10/1000 \t Current score: 1.4755 | Avg score over 100 episodes: 1.0431\n",
      "Elapsed time:   3 minutes  5 seconds\n",
      "\n",
      "Episode   15/1000 \t Current score: 2.6620 | Avg score over 100 episodes: 1.5084\n",
      "Elapsed time:   4 minutes 46 seconds\n",
      "\n",
      "Episode   20/1000 \t Current score: 6.5305 | Avg score over 100 episodes: 2.4667\n",
      "Elapsed time:   6 minutes 38 seconds\n",
      "\n",
      "Episode   25/1000 \t Current score: 19.4920 | Avg score over 100 episodes: 5.1008\n",
      "Elapsed time:   8 minutes 40 seconds\n",
      "\n",
      "Episode   30/1000 \t Current score: 29.2980 | Avg score over 100 episodes: 8.8444\n",
      "Elapsed time:  10 minutes 56 seconds\n",
      "\n",
      "Episode   35/1000 \t Current score: 35.1355 | Avg score over 100 episodes: 12.5051\n",
      "Elapsed time:  13 minutes 24 seconds\n",
      "\n",
      "Episode   40/1000 \t Current score: 38.0010 | Avg score over 100 episodes: 15.5925\n",
      "Elapsed time:  16 minutes  5 seconds\n",
      "\n",
      "Episode   45/1000 \t Current score: 38.4430 | Avg score over 100 episodes: 18.1159\n",
      "Elapsed time:  18 minutes 58 seconds\n",
      "\n",
      "Episode   50/1000 \t Current score: 38.3260 | Avg score over 100 episodes: 20.1332\n",
      "Elapsed time:  22 minutes  4 seconds\n",
      "\n",
      "Episode   55/1000 \t Current score: 38.5510 | Avg score over 100 episodes: 21.7899\n",
      "Elapsed time:  25 minutes 17 seconds\n",
      "\n",
      "Episode   60/1000 \t Current score: 38.9320 | Avg score over 100 episodes: 23.1459\n",
      "Elapsed time:  28 minutes 30 seconds\n",
      "\n",
      "Episode   65/1000 \t Current score: 37.9985 | Avg score over 100 episodes: 24.3100\n",
      "Elapsed time:  31 minutes 43 seconds\n",
      "\n",
      "Episode   70/1000 \t Current score: 38.6985 | Avg score over 100 episodes: 25.2853\n",
      "Elapsed time:  34 minutes 56 seconds\n",
      "\n",
      "Episode   75/1000 \t Current score: 38.2860 | Avg score over 100 episodes: 26.1154\n",
      "Elapsed time:  38 minutes 10 seconds\n",
      "\n",
      "Episode   80/1000 \t Current score: 37.5435 | Avg score over 100 episodes: 26.8647\n",
      "Elapsed time:  41 minutes 24 seconds\n",
      "\n",
      "Episode   85/1000 \t Current score: 37.8425 | Avg score over 100 episodes: 27.5034\n",
      "Elapsed time:  44 minutes 38 seconds\n",
      "\n",
      "Episode   90/1000 \t Current score: 36.3995 | Avg score over 100 episodes: 28.0452\n",
      "Elapsed time:  47 minutes 51 seconds\n",
      "\n",
      "Episode   95/1000 \t Current score: 37.1195 | Avg score over 100 episodes: 28.5066\n",
      "Elapsed time:  51 minutes  4 seconds\n",
      "\n",
      "Episode  100/1000 \t Current score: 37.2830 | Avg score over 100 episodes: 28.9488\n",
      "Elapsed time:  54 minutes 18 seconds\n",
      "\n",
      "The environment is solved in 103 episodes with an average score of 30.0613 over 100 episodes\n",
      "Elapsed time:  56 minutes 15 seconds\n"
     ]
    }
   ],
   "source": [
    "with active_session():\n",
    "    scores = train_agent(env, brain_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8c4340dba8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.plot_scores(scores, \"Average score (over 100 episodes and over all 20 agents)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [distributional version](https://openreview.net/forum?id=SyZipzbCb) of the algorithm used is the logical next step to improve the performance. The linked paper uses a categorical distribution with 51 atoms. According to the paper, the use of distributional \"Critic\" update leads to an improvement over the non-distributional version of the algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
